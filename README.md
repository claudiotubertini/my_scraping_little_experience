## My crawling experience
Here you find a few examples of crawlers prepared in the past couple of years on behalf of some customers.
1. `products_crawling.R`
A simple crawler written in R that downloads products public information. The crawler access all the pages of the
target e-commerce site, downloads the information and create a data frame.
The pages are divided by categories and page numbers.
2. `selenium.py`
A slightly more complex crawler of web pages generated by a javascript application. It is written in python and make use of Selenium.
3. `unibo_iteration.py`
A python crawler that saves results in a mongodb database.
4. `crawling_names_unibo.R` and `scrape_unibo_single_page.js`
An R crawler that make use of PhantomJS in a javascript application
5. `customers.py`
A crawler that make use of Mechanize and BeautifulSoup.

Other files are simple studies and examples.